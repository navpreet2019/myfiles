{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f867149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import metrics\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df670c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_x = np.random.randn(100)*5\n",
    "toy_y = 1+toy_x + np.random.randn(100)*3\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(toy_x, toy_y)\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_xlabel(r\"$x_1$\")\n",
    "ax.set_ylabel(r\"$x_2$\")\n",
    "sns.despine(ax=ax, trim=True)\n",
    "ax.set_title(\"raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_pca = PCA(1)\n",
    "toy_down = toy_pca.fit_transform(np.vstack([toy_x, toy_y]).T)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(toy_down, [0]*len(toy_down))\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_xlabel(r\"$PC_1$\")\n",
    "sns.despine(ax=ax, trim=True, left=True)\n",
    "ax.set_title(\"PCA transformed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_up = np.dot(toy_down, toy_pca.components_) + toy_pca.mean_\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(*toy_up.T)\n",
    "ax.scatter(toy_x, toy_y, c='k', alpha=.1)\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_ylim(-20,20)\n",
    "ax.set_xlabel(r\"$\\hat{x}_1$\")\n",
    "ax.set_ylabel(r\"$\\hat{x}_2$\")\n",
    "sns.despine(ax=ax, trim=True)\n",
    "ax.set_title(\"reconstructed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 2\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='linear')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='linear')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93234cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder/linear-2d')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(2)\n",
    "pca_model.fit(x_train)\n",
    "pca_encoded_imgs = pca_model.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041375c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_decoded_imgs = np.dot(pca_encoded_imgs, pca_model.components_) + pca_model.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9920a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(pca_decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = sns.color_palette(\"Set3\", len(set(y_test)))\n",
    "y2col = { y:c for y,c in zip(set(y_test), pal)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(pca_encoded_imgs[:,0], pca_encoded_imgs[:,1], c=[y2col[y] for y in y_test])\n",
    "ax.legend(handles=[mpatches.Patch(color=c, label=y) for y,c in y2col.items()], bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a52310",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=256)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=[y2col[y] for y in y_test])\n",
    "ax.legend(handles=[mpatches.Patch(color=c, label=y) for y,c in y2col.items()], bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a63b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                          NON LINEAR AUTOENCODERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder/nonlinear-ae')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "                  Nonlinear autoencoder with only 2 latent dimensions (no intermediate layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 2\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder/nonlinear-2d')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3031f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(encoded_imgs[:,0], encoded_imgs[:,1], c=[y2col[y] for y in y_test])\n",
    "ax.legend(handles=[mpatches.Patch(color=c, label=y) for y,c in y2col.items()], bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a84fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "                            Nonlinear, deep autoencoder (one intermediary layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(256, activation='relu')(input_img)\n",
    "encoded = Dense(2, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder/deep-autoencoder-2dims')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633576e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(encoded_imgs[:,0], encoded_imgs[:,1], c=[y2col[y] for y in y_test])\n",
    "ax.legend(handles=[mpatches.Patch(color=c, label=y) for y,c in y2col.items()], bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "n = 20  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "# grid_x = stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "# grid_y = stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_x = np.linspace(0,50,n)\n",
    "grid_y = np.linspace(0,50,n)\n",
    "\n",
    "# predicteds = decoder.predict(np.vstack([grid_x, grid_y]).T)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        x_decoded = decoder.predict(np.array([[xi, yi]]))\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[(n-1-i) * digit_size: (n-i) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, origin='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epochs = 20\n",
    "epsilon_std = 1.0\n",
    "\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21357d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n",
    "# Compute VAE loss\n",
    "xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "beta = .1\n",
    "vae_loss = K.mean(xent_loss + beta*kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "%%time\n",
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None),\n",
    "        callbacks=[TensorBoard(log_dir='/tmp/autoencoder/vae')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = generator.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70395182",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=[y2col[y] for y in y_test])\n",
    "ax.legend(handles=[mpatches.Patch(color=c, label=y) for y,c in y2col.items()], bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61feffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "n = 20  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "# grid_x = stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "# grid_y = stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_x = np.linspace(-10,10,n)\n",
    "grid_y = np.linspace(-10,10,n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[(n-1-i) * digit_size: (n-i) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, origin='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4567e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
